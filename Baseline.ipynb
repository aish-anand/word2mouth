{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ftfy\n",
    "import unidecode\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handle anomalies/clean data\n",
    "food_dict = pd.read_csv(\"D:\\\\UMass\\\\Fall 18\\\\COMPSCI 585 NLP\\\\Project\\\\food_dict.csv\", encoding=\"UTF-8\")\n",
    "food_dict['food'] = food_dict.astype(str)\n",
    "food_dict.drop(['scrape_id'], inplace = True, axis = 1)\n",
    "\n",
    "food_dict['food'] = food_dict['food'].apply(lambda x: x.lower())\n",
    "food_dict['food'] = food_dict['food'].apply(lambda x: unidecode.unidecode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to list and save as pickle\n",
    "food_list = food_dict['food'].tolist()\n",
    "file_Name = \"food_dictionary\"\n",
    "fileObject = open(file_Name,'wb') #wb - raw binary, remember to open the file in rb mode\n",
    "pickle.dump(food_list,fileObject)   \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "reviews_df = pd.read_csv(\"all_reviews.csv\")\n",
    "business_df = pd.read_csv(\"business.csv\")\n",
    "menus_df = pd.read_csv(\"all_menus.csv\")\n",
    "bakery_reviews = reviews_df[reviews_df['business_id'] == 1116]['text'].tolist() # tartine bakery and cafe\n",
    "bakery_menu = menus_df[menus_df['business_id'] == 1116]['menu_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "sentences = []\n",
    "for paragraph in bakery_reviews:\n",
    "    lines_list = tokenize.sent_tokenize(paragraph)\n",
    "    sentences.extend(lines_list)\n",
    "#create a set for fast access!\n",
    "food_set = set(food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# get spans with positions\n",
    "def spans(txt):\n",
    "    tokens= word_tokenize(txt)\n",
    "    offset = 0\n",
    "    for token in tokens:\n",
    "        offset = txt.find(token, offset)\n",
    "        yield token, offset, offset+len(token)\n",
    "        offset += len(token)\n",
    "\n",
    "# get mentions\n",
    "def find_mentions(s, with_stemming = True):\n",
    "    mentions = []\n",
    "    for token in spans(s):\n",
    "        if with_stemming:\n",
    "            t = stemmer.stem(token[0])\n",
    "        else:\n",
    "            t = token[0]\n",
    "        if t in food_set:\n",
    "            mentions.append((t, token[1], token[2]))#return the stemmed version but the positions are still from the sentence\n",
    "    return merge_mentions(mentions)\n",
    "\n",
    "# merge adjoining mentions to create a multiword mention \n",
    "def merge_mentions(intervals):\n",
    "    out = []\n",
    "    for i in sorted(intervals, key=lambda i: i[1]):\n",
    "        if out and (i[1] - out[-1][2]) == 1:\n",
    "            new_mention = out[-1][0] + \" \" + i[0]\n",
    "            new_start = out[-1][1]\n",
    "            new_end = i[2]\n",
    "#             print(new_mention)\n",
    "            out.pop()\n",
    "            out.append((new_mention, new_start, new_end))\n",
    "        else:\n",
    "            out.append(i)\n",
    "    return out\n",
    "\n",
    "# get a set of menu items/dishes which we picked out\n",
    "def get_possible_menu(dict_mentions):\n",
    "    possible_menu_items = set()\n",
    "    for mentions in dict_mentions.values():\n",
    "        if mentions:\n",
    "#             print(mentions)\n",
    "            for m in mentions:\n",
    "                possible_menu_items.add(m[0])\n",
    "    return possible_menu_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_possible_menu(new_dict_mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Stemming (snowball stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_mentions = {}\n",
    "for s in sentences:\n",
    "    mentions = find_mentions(s)\n",
    "    dict_mentions[s] = mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: The baseline is heavily dependent on the preprocessing steps and the way the sentence is structured. \n",
    "Example sentence : if i had more money, i would be awash in coconut cream pies, lemon cream tarts, and morning buns with a hint of orange . \n",
    "Output without stemming : [('coconut', 41, 48),  ('cream', 49, 54), ('lemon', 61, 66),  ('cream', 67, 72), ('orange', 112, 118)] Snowball stemmer : [('coconut', 41, 48), ('cream', 49, 54), ('pies', 55, 59), ('lemon', 61, 66), ('cream', 67, 72),  ('tarts', 73, 78),  ('buns', 92, 96)] Orange which is a common word and found in the food dictionary is missing because it's stem is 'orang' which is not found in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menus_with_stemming = get_possible_menu(dict_mentions)\n",
    "len(menus_with_stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This is looks pretty good! Some good examples are 'coconut cream tart' and 'cinnamon roll'. However a lot of simple things didn't get picked up. Let's see how many of these are actually on the menu for the restaurant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menus_df[(menus_df['menu_items'].isin(menus_with_stemming)) & (menus_df['business_id'] == 1116)].shape[0]\n",
    "# print(\"Matching items : \", m_items.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_items = menus_df[menus_df['menu_items'].isin(menu_without_stemming) & (menus_df['business_id'] == 1116)]\n",
    "print(\"Matching items: \", matching_items.shape[0])\n",
    "total_menu_items = menus_df[(menus_df['business_id'] == 1116)]\n",
    "print(\"Matching items: \", total_menu_items.shape[0])\n",
    "print(\"% matching items - \", (matching_items.shape[0]/total_menu_items.shape[0])*100)\n",
    "# matching_items\n",
    "print(\"Prec :\", (matching_items.shape[0]/len(menu_without_stemming))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_mentions(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_dict_mentions = {}\n",
    "for s in sentences:\n",
    "    mentions = find_mentions(s, with_stemming = False)\n",
    "    new_dict_mentions[s] = mentions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dict_mentions\n",
    "for key,val in dict_mentions.items():\n",
    "    if key in new_dict_mentions:\n",
    "        new_dict_mentions[key] = [new_dict_mentions[key],val]\n",
    "        \n",
    "with open(\"D:\\\\UMass\\\\Fall 18\\\\COMPSCI 585 NLP\\\\Project\\\\baseline_no_stemming.txt\", \"w\") as text_file:\n",
    "        text_file.write(str(new_dict_mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_without_stemming = get_possible_menu(new_dict_mentions)\n",
    "matching_items = menus_df[menus_df['menu_items'].isin(menu_without_stemming) & (menus_df['business_id'] == 1116)]\n",
    "print(\"Matching items: \", matching_items.shape[0])\n",
    "total_menu_items = menus_df[(menus_df['business_id'] == 1116)]\n",
    "print(\"Matching items: \", total_menu_items.shape[0])\n",
    "print(\"% matching items - \", matching_items.shape[0]/total_menu_items.shape[0]*100)\n",
    "# matching_items\n",
    "print(\"Prec :\", matching_items.shape[0]/len(menu_without_stemming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menus_df[(menus_df['business_id'] == 1116)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem('cookie')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
