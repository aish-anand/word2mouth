{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 1,
   "metadata": {},
>>>>>>> 2e031a00d242b4623040ec08fdf964e7c188be41
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog cat 0.53906965\n",
      "dog banana 0.28761005\n",
      "cat dog 0.53906965\n",
      "cat cat 1.0\n",
      "cat banana 0.4875216\n",
      "banana dog 0.28761005\n",
      "banana cat 0.4875216\n",
      "banana banana 1.0\n"
     ]
    }
   ],
>>>>>>> 2e031a00d242b4623040ec08fdf964e7c188be41
   "source": [
    "# sample spacy similarity\n",
    "nlp = spacy.load('en')  # make sure to use larger model -> later\n",
    "tokens = nlp(u'dog cat banana')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all CSV files\n",
    "pred_ents = pd.read_csv(\"predictions.csv\")\n",
    "# reviews = pd.read_csv(\"all_reviews.csv\")\n",
    "# menus = pd.read_csv(\"all_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine reviews and annotations; drop unnecessary cols\n",
    "print(\"predicted entities = \",pred_ents.shape)\n",
    "print(\"reviews = \",reviews.shape)\n",
    "reviews_with_ents = reviews.merge(right = pred_ents,how = 'inner',on ='review_id', sort = True)\n",
    "print(\"Merged = \", reviews_with_ents.shape)\n",
    "reviews_with_ents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_with_ents.drop(['user_name', 'business_id_y'], axis = 1, inplace = True)\n",
    "reviews_with_ents.columns = ['review_id', 'business_id', 'stars', 'date', 'text', 'entities']\n",
    "reviews_with_ents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ents['entities'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews['sentences'] = reviews['text'].apply(lambda x: x.split('.'))\n",
    "reviews['sentences'] = reviews['sentences'].apply(lambda x: [s.strip() for s in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = reviews.apply(lambda x: pd.Series(x['sentences']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'sentence'\n",
    "sent_tokenize_reviews = reviews.drop('sentences', axis=1).join(s).drop('text', axis = 1)\n",
    "sent_tokenize_reviews.shape\n",
    "sent_pred_ents = pd.read_csv(\"predictions_sentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "sent_pred_ents = pd.read_csv(\"predictions_sentence.csv\")\n",
    "sent_pred_ents['entities'] = sent_pred_ents['entities'].apply(literal_eval)\n",
    "sent_pred_ents['len'] = sent_pred_ents['entities'].apply(lambda x: len(x))\n",
    "agg1 = sent_pred_ents.groupby(['review_id', 'business_id']).agg({'len' : 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pred_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_ents['entities'] = pred_ents['entities'].apply(literal_eval)\n",
    "pred_ents['len'] = pred_ents['entities'].apply(lambda x: len(x))\n",
    "agg2 = pred_ents.groupby(['review_id','business_id']).agg({'len':'sum'})\n",
    "agg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = agg1.merge(right = agg2, how = 'inner', on = 'review_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m['len_x'] = pd.to_numeric(m['len_x'])\n",
    "m['len_y'] = pd.to_numeric(m['len_y'])\n",
    "m['check'] = abs(m['len_x'] - m['len_y'])\n",
    "print(sum(m['len_x']))\n",
    "print(sum(m['len_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [['Alex',10],['Bob',12],['Clarke',13]]\n",
    "df = pd.DataFrame(data,columns=['Name','Age'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_diff = m[m['check'] > 3]\n",
    "s = large_diff['review_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_pred_ents[sent_pred_ents['review_id'].isin(s)].to_csv(\"new_missing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Between Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast  import literal_eval\n",
    "pred_ann_snt = pd.read_csv(\"predictions_sentence_sentiment.csv\", encoding = 'utf8')\n",
    "pred_ann_snt['entities'] = pred_ann_snt['entities'].apply(literal_eval)\n",
    "pred_ann_snt['len'] = pred_ann_snt['entities'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35869, 10)\n",
      "(11298, 9)\n"
     ]
    }
   ],
   "source": [
    "print(pred_ann_snt.shape)\n",
    "pred_ann_snt.drop(pred_ann_snt[pred_ann_snt.len < 1].index, inplace=True)\n",
    "pred_ann_snt.drop(columns='len', inplace=True)\n",
    "print(pred_ann_snt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_dict = {}\n",
    "unique_b_id = pred_ann_snt['business_id'].unique()\n",
    "unique_b_id\n",
    "\n",
    "pred_ann_snt['food'] = pred_ann_snt['entities'].apply(lambda x: [a[0] for a in x])\n",
    "pred_ann_snt.head()\n",
    "\n",
    "for b_id in unique_b_id:\n",
    "    menu_dict[b_id] = pred_ann_snt[pred_ann_snt['business_id'] == b_id]['food'].values.tolist()\n",
    "\n",
    "for k in menu_dict.keys():\n",
    "    print(k)\n",
    "    items = set()\n",
    "    for l in menu_dict.get(k, \"\"):\n",
    "#         print(l)\n",
    "        items = items.union(set(l))\n",
    "    menu_dict[k] = list(items)\n",
    "\n",
    "    \n",
    "# similarity with  spacy\n",
    "sim_list = []\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        sim_list.append((token1.text, token2.text, token1.similarity(token2)))\n",
    "\n",
    "# from itertools import ifilter\n",
    "filtered = [item for item in sim_list if item[2]>0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"filtered_sim_list.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity with substring match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in menu_dict.keys():\n",
    "    menu = menu_dict.get(k, \"\")\n",
    "    print(len(menu))\n",
    "    for item1 in menu:\n",
    "        for item2 in menu:\n",
    "            if len(item1) > len(item2) and item2 in item1:\n",
    "                if item2 in menu:\n",
    "                    menu.remove(item2)\n",
    "            elif len(item2) > len(item1) and item1 in item2:\n",
    "                if item1 in menu:\n",
    "                    menu.remove(item1)\n",
    "    menu_dict[k] = menu\n",
    "\n",
    "#substring match\n",
    "import pickle\n",
    "pickle.dump(menu_dict, open( \"menu_dict_substring_match.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fuzzy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Match!\n",
      "1118 165\n",
      "1116 238\n",
      "1120 414\n",
      "1117 185\n",
      "1119 200\n",
      "1126 677\n",
      "1127 377\n",
      "1128 637\n",
      "1129 229\n",
      "1130 860\n",
      "1122 240\n",
      "1121 123\n",
      "1123 241\n",
      "1124 238\n",
      "1125 291\n",
      "1111 342\n",
      "1112 145\n",
      "1113 231\n",
      "1114 146\n",
      "1115 284\n",
      "After match!\n",
      "1118 157\n",
      "1116 214\n",
      "1120 357\n",
      "1117 143\n",
      "1119 179\n",
      "1126 538\n",
      "1127 301\n",
      "1128 510\n",
      "1129 178\n",
      "1130 776\n",
      "1122 203\n",
      "1121 97\n",
      "1123 218\n",
      "1124 215\n",
      "1125 252\n",
      "1111 309\n",
      "1112 133\n",
      "1113 206\n",
      "1114 129\n",
      "1115 239\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "#create a raw menu from mentions\n",
    "menu_dict_fuzz = {}\n",
    "unique_b_id = pred_ann_snt['business_id'].unique()\n",
    "unique_b_id\n",
    "\n",
    "pred_ann_snt['food'] = pred_ann_snt['entities'].apply(lambda x: [a[0] for a in x])\n",
    "pred_ann_snt.head()\n",
    "\n",
    "for b_id in unique_b_id:\n",
    "    menu_dict_fuzz[b_id] = pred_ann_snt[pred_ann_snt['business_id'] == b_id]['food'].values.tolist()\n",
    "\n",
    "for k in menu_dict_fuzz.keys():\n",
    "#     print(k)\n",
    "    items = set()\n",
    "    for l in menu_dict_fuzz.get(k, \"\"):\n",
    "        items = items.union(set(l))\n",
    "    menu_dict_fuzz[k] = list(items)\n",
    "\n",
    "print(\"Before Match!\")\n",
    "for k in menu_dict_fuzz.keys():\n",
    "    print(k, len(menu_dict_fuzz.get(k, \"\")))\n",
    "    \n",
    "for k in menu_dict_fuzz.keys():\n",
    "    menu = menu_dict_fuzz.get(k, \"\")\n",
    "#     print(len(menu))\n",
    "    for item1 in menu:\n",
    "        for item2 in menu:\n",
    "            if fuzz.ratio(item1,item2)  > 80 and item1 != item2:\n",
    "#                 print(item1,\" , \", item2, \" score = \", fuzz.ratio(item1, item2))\n",
    "                if len(item1) > len(item2):\n",
    "                    if item2 in menu:\n",
    "                        menu.remove(item2)\n",
    "                elif len(item2) > len(item1):\n",
    "                    if item1 in menu:\n",
    "                        menu.remove(item1)\n",
    "    menu_dict_fuzz[k] = menu\n",
    "\n",
    "print(\"After match!\")\n",
    "for k in menu_dict_fuzz.keys():\n",
    "    print(k, len(menu_dict_fuzz.get(k, \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substring match\n",
    "import pickle\n",
    "pickle.dump(menu_dict_fuzz, open( \"menu_dict_fuzzy_match.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No similarity match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a raw menu from mentions\n",
    "menu_dict_plain = {}\n",
    "unique_b_id = pred_ann_snt['business_id'].unique()\n",
    "unique_b_id\n",
    "\n",
    "pred_ann_snt['food'] = pred_ann_snt['entities'].apply(lambda x: [a[0] for a in x])\n",
    "pred_ann_snt.head()\n",
    "\n",
    "for b_id in unique_b_id:\n",
    "    menu_dict_plain[b_id] = pred_ann_snt[pred_ann_snt['business_id'] == b_id]['food'].values.tolist()\n",
    "\n",
    "for k in menu_dict_fuzz.keys():\n",
    "#     print(k)\n",
    "    items = set()\n",
    "    for l in menu_dict_plain.get(k, \"\"):\n",
    "        items = items.union(set(l))\n",
    "    menu_dict_plain[k] = list(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business id:  1116\n",
      "Menu item found with fuzzy match -  7.777777777777778\n",
      "Menu item found with substring match -  7.777777777777778\n",
      "Menu item found with no similiarity match -  11.11111111111111\n",
      "Business id:  1117\n",
      "Menu item found with fuzzy match -  7.5\n",
      "Menu item found with substring match -  5.0\n",
      "Menu item found with no similiarity match -  15.0\n",
      "Business id:  1118\n",
      "Menu item found with fuzzy match -  3.125\n",
      "Menu item found with substring match -  3.125\n",
      "Menu item found with no similiarity match -  3.125\n",
      "Business id:  1119\n",
      "Menu item found with fuzzy match -  3.6363636363636362\n",
      "Menu item found with substring match -  5.454545454545454\n",
      "Menu item found with no similiarity match -  9.090909090909092\n",
      "Business id:  1120\n",
      "Menu item found with fuzzy match -  17.5\n",
      "Menu item found with substring match -  17.5\n",
      "Menu item found with no similiarity match -  35.0\n",
      "Business id:  1126\n",
      "Menu item found with fuzzy match -  25.0\n",
      "Menu item found with substring match -  20.0\n",
      "Menu item found with no similiarity match -  62.5\n",
      "Business id:  1127\n",
      "Menu item found with fuzzy match -  13.88888888888889\n",
      "Menu item found with substring match -  7.638888888888889\n",
      "Menu item found with no similiarity match -  18.75\n",
      "Business id:  1128\n",
      "Menu item found with fuzzy match -  4.3478260869565215\n",
      "Menu item found with substring match -  2.1739130434782608\n",
      "Menu item found with no similiarity match -  10.869565217391305\n",
      "Business id:  1129\n",
      "Menu item found with fuzzy match -  8.0\n",
      "Menu item found with substring match -  4.0\n",
      "Menu item found with no similiarity match -  44.0\n",
      "Business id:  1130\n",
      "Menu item found with fuzzy match -  38.88888888888889\n",
      "Menu item found with substring match -  11.11111111111111\n",
      "Menu item found with no similiarity match -  66.66666666666666\n",
      "Business id:  1121\n",
      "Menu item found with fuzzy match -  4.761904761904762\n",
      "Menu item found with substring match -  4.761904761904762\n",
      "Menu item found with no similiarity match -  28.57142857142857\n",
      "Business id:  1123\n",
      "Menu item found with fuzzy match -  5.405405405405405\n",
      "Menu item found with substring match -  5.405405405405405\n",
      "Menu item found with no similiarity match -  13.513513513513514\n",
      "Business id:  1122\n",
      "Menu item found with fuzzy match -  9.375\n",
      "Menu item found with substring match -  12.5\n",
      "Menu item found with no similiarity match -  18.75\n",
      "Business id:  1124\n",
      "Menu item found with fuzzy match -  0.0\n",
      "Menu item found with substring match -  0.8264462809917356\n",
      "Menu item found with no similiarity match -  3.3057851239669422\n",
      "Business id:  1125\n",
      "Menu item found with fuzzy match -  1.8518518518518516\n",
      "Menu item found with substring match -  1.8518518518518516\n",
      "Menu item found with no similiarity match -  1.8518518518518516\n",
      "Business id:  1111\n",
      "Menu item found with fuzzy match -  5.405405405405405\n",
      "Menu item found with substring match -  5.405405405405405\n",
      "Menu item found with no similiarity match -  6.486486486486487\n",
      "Business id:  1112\n",
      "Menu item found with fuzzy match -  5.714285714285714\n",
      "Menu item found with substring match -  5.714285714285714\n",
      "Menu item found with no similiarity match -  5.714285714285714\n",
      "Business id:  1114\n",
      "Menu item found with fuzzy match -  0.0\n",
      "Menu item found with substring match -  0.0\n",
      "Menu item found with no similiarity match -  41.66666666666667\n",
      "Business id:  1113\n",
      "Menu item found with fuzzy match -  6.944444444444445\n",
      "Menu item found with substring match -  8.333333333333332\n",
      "Menu item found with no similiarity match -  11.11111111111111\n",
      "Business id:  1115\n",
      "Menu item found with fuzzy match -  35.13513513513514\n",
      "Menu item found with substring match -  13.513513513513514\n",
      "Menu item found with no similiarity match -  45.94594594594595\n"
     ]
    }
   ],
   "source": [
    "for k in actual_menus.keys():\n",
    "    print(\"Business id: \", k)\n",
    "    menu_size = len(actual_menus.get(k, \"\"))\n",
    "    fuzz_count = 0\n",
    "    substr_count = 0\n",
    "    plain_count = 0 \n",
    "    fuzz_count += len(set(actual_menus.get(k, \"\")) & set(menu_dict_fuzz.get(k, \"\")))\n",
    "    substr_count += len(set(actual_menus.get(k, \"\")) & set(menu_dict.get(k, \"\")))\n",
    "    plain_count += len(set(actual_menus.get(k, \"\")) & set(menu_dict_plain.get(k, \"\")))\n",
    "    print(\"Menu item found with fuzzy match - \", fuzz_count/menu_size*100)\n",
    "    print(\"Menu item found with substring match - \", substr_count/menu_size*100)\n",
    "    print(\"Menu item found with no similiarity match - \", plain_count/menu_size*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
